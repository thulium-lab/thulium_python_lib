{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "from IPython.html.widgets import FloatProgress\n",
    "from IPython.display import display\n",
    "from matplotlib.cbook import flatten\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removed coeffitioent 2 in gaussian functions in exponents\n",
    "def gaussian(x,N,x0,sigma, background):\n",
    "    \"\"\"Returns value of a 1D-gaussian with the given parameters\"\"\"\n",
    "    #from numpy import sqrt,pi,exp\n",
    "    return N / (sigma * sqrt(pi)) * exp(-(x - x0)**2/(sigma**2)) + background\n",
    "\n",
    "def gaussian2D(N, x0, y0, sigma_x, sigma_y, background):\n",
    "    \"\"\"Returns a 2D-gaussian function with the given parameters\"\"\"\n",
    "    #from numpy import pi,exp\n",
    "    sigma_x = float(sigma_x)\n",
    "    sigma_y = float(sigma_y)\n",
    "    return lambda x,y: N / (sigma_x * sigma_y  * pi) * exp(\n",
    "                        -(((x - x0) / sigma_x)**2 + ((y - y0) / sigma_y)**2)) + background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Image_Basics():\n",
    "    \"\"\"Basic image processing, with only center determination and background substructing. \n",
    "        isgood parameter is needed for indicating if smth wrong with image during it's processing \n",
    "        (i.e. if image is blank)\"\"\"\n",
    "    def __init__(self,image):\n",
    "        if not hasattr(self,'image_url'):\n",
    "            self.image_url = 'derived'\n",
    "        self.image = image\n",
    "        c_pos = self.image.argmax()\n",
    "        self.center_pos = (c_pos//self.image.shape[1], c_pos%self.image.shape[1])\n",
    "        self.image = self.bgd_substract()\n",
    "        self.total = sum(self.image)\n",
    "        self.isgood = True\n",
    "    def bgd_substract(self, slice_to_c = (-20,-1)):\n",
    "        \"\"\" Substracts background, which is calculated using vertical strip at right side\"\"\"\n",
    "        data_for_bgd_det = self.image[:,slice_to_c[0]:slice_to_c[1]]\n",
    "        av = sum(data_for_bgd_det,1)/data_for_bgd_det.shape[1]\n",
    "        return self.image - tile(av[:,newaxis],self.image.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Image_Fitted(Image_Basics):\n",
    "    \"\"\" Ads fitting functionality, namle 1D and 2D gauss fit\n",
    "        If fitting has failed, it prints error message and delites this image from data\n",
    "        x_data_fit = [total, x0, sigma_x, background]\n",
    "        y_data_fit = [total, y0, sigma_y, background]\n",
    "        fit2D = [total, y0, x0, sigma_y, sigma_x, background]\"\"\"\n",
    "    def __init__(self, image, do_fit2D, do_filtering=False):\n",
    "        from scipy.ndimage import gaussian_filter, median_filter\n",
    "        Image_Basics.__init__(self,image)\n",
    "        if do_filtering:\n",
    "            self.image = gaussian_filter(self.image,1)\n",
    "        try:\n",
    "            self.do_fit(do_fit2D)\n",
    "            self.center_pos = (self.x_data_fit[1], self.y_data_fit[1])\n",
    "        except RuntimeError:\n",
    "            print(\"RuntimeError, couldn't find fit for image\", self.image_url)\n",
    "            self.isgood = False\n",
    "    def do_fit(self, do_fit2D, width=10):\n",
    "        \"\"\" Does fits\"\"\"\n",
    "        from scipy.optimize import curve_fit\n",
    "        x_data = sum(self.image,0)\n",
    "        y_data = sum(self.image,1)\n",
    "        popt_x, pcov_x = curve_fit(gaussian, range(len(x_data)), x_data, p0=(self.total, argmax(x_data), width, 0))\n",
    "        popt_y, pcov_y = curve_fit(gaussian, range(len(y_data)), y_data, p0=(self.total, argmax(y_data), width, 0))\n",
    "        self.x_data_fit = popt_x\n",
    "        self.y_data_fit = popt_y\n",
    "        if do_fit2D:\n",
    "            self.fit2D = self.fitgaussian2D()\n",
    "    def fitgaussian2D(self):\n",
    "        \"\"\"Returns (height, y, x, width_y, width_x)\n",
    "        the gaussian parameters of a 2D distribution found by a fit\"\"\"\n",
    "        from scipy import optimize\n",
    "        params = (self.total, self.y_data_fit[1], self.x_data_fit[1], self.y_data_fit[2], self.x_data_fit[2], 0)\n",
    "        errorfunction = lambda p: ravel(gaussian2D(*p)(*indices(self.image.shape)) -\n",
    "                                 self.image)\n",
    "        p, success = optimize.leastsq(errorfunction, params)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Image_Load(Image_Fitted):\n",
    "    \"\"\" Loads image using relative path, based on Image_Fitted\"\"\"\n",
    "    def __init__(self,image_url, do_fit2D=False, do_filtering=False):\n",
    "        from matplotlib.pyplot import imread\n",
    "        from re import findall\n",
    "        self.image_url = image_url\n",
    "        Image_Fitted.__init__(self, imread(image_url), do_fit2D, do_filtering)\n",
    "        (self.folderN, self.shotN, self.shot_typeN) = map(float, findall(r\"[-+]?\\d*\\.\\d+|\\d+\", self.image_url)[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Avr_inf(Image_Fitted):\n",
    "    \"\"\" Class for average data, has all attributes as Image_Fitted instance for average image as well as average\n",
    "        data from each image:\n",
    "        each_x_data_fit = [total, x0, sigma_x, background]\n",
    "        each_y_data_fit = [total, y0, sigma_y, background]\n",
    "        each_fit2D = [total, y0, x0, sigma_y, sigma_x, background] if exists\n",
    "        \"\"\"\n",
    "    def __init__(self,shot_list, do_fit2D=True):\n",
    "        Image_Fitted.__init__(self,mean([d.image for d in shot_list],0), do_fit2D)\n",
    "        self.each_x_data_fit = mean([d.x_data_fit for d in shot_list],0)\n",
    "        self.each_y_data_fit = mean([d.y_data_fit for d in shot_list],0)\n",
    "        if hasattr(shot_list[0],'fit2D'):\n",
    "            self.each_fit2D = mean([d.fit2D for d in shot_list],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(directory, do_fit2D = False, do_filtering=False):\n",
    "    \"\"\"Loads all data from 'directory' initially to all_data (unsorted list), and then to dictionary structure dataD\n",
    "    folderN1  ----    shot_typeN1   ----  [list of Image_Load instances]\n",
    "                      shot_typeN2   ----  [list of Image_Load instances]\n",
    "                     ....\n",
    "    folderN2  ----    shot_typeN1   ----  [list of Image_Load instances]\n",
    "                      shot_typeN2   ----  [list of Image_Load instances]\n",
    "                     ....\n",
    "    By default does not fit each image 2D-gauss\"\"\"\n",
    "    import os, re\n",
    "    dirs = [os.path.join(directory,dr) for dr in os.listdir(directory) if re.match(r'[-+]?[0-9.]+ms',dr)]\n",
    "    all_data = []\n",
    "    w = FloatProgress(min=0, max=len(dirs),value=0)\n",
    "    w.description='Loading in progress...'\n",
    "    display(w)\n",
    "    for dr in dirs:\n",
    "        w.value += 1\n",
    "        files = [os.path.join(dr,fl) for fl in os.listdir(dr) if re.match(r'.*_\\d+.png',fl)]\n",
    "        for url in files:\n",
    "            new_im = Image_Load(url, do_fit2D, do_filtering)\n",
    "            if new_im.isgood:\n",
    "                all_data.append(new_im)\n",
    "    w.bar_style='success'\n",
    "    w.description = 'Loading Done'\n",
    "#     all_data = list(flatten(map(single_directory_load, dirs ,[do_fit2D]*len(dirs), [do_filtering]*len(dirs))))\n",
    "    print('Total number of images: ', len(all_data))\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_directory_load(dr, do_fit2D, do_filtering):\n",
    "    \"\"\"Function to use in parallel data load\"\"\"\n",
    "    import os, re\n",
    "    files = [os.path.join(dr,fl) for fl in os.listdir(dr) if re.match(r'.*_\\d+.png',fl)]\n",
    "    temp_arr = []\n",
    "    for url in files:\n",
    "        new_im = Image_Load(url, do_fit2D, do_filtering)\n",
    "        if new_im.isgood:\n",
    "            temp_arr.append(new_im)\n",
    "    return temp_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rearrange_data(all_data):\n",
    "    dataD = dict()\n",
    "    w = FloatProgress(min=0, max=len(all_data),value=0)\n",
    "    w.description='Rearranging in progress...'\n",
    "    display(w)\n",
    "    for elem in all_data:\n",
    "        w.value +=1\n",
    "        if elem.folderN not in dataD:\n",
    "            dataD[elem.folderN] = dict()\n",
    "        d = dataD[elem.folderN]\n",
    "        if elem.shot_typeN not in d:\n",
    "            d[elem.shot_typeN] = []\n",
    "        d[elem.shot_typeN].append(elem)\n",
    "    w.bar_style='success'\n",
    "    w.description = 'Rearranging Done'\n",
    "    print('Rearranging to dictionary is complited')\n",
    "    return dataD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_data(dataD, do_fit2D=True):\n",
    "    \"\"\"Averages data from dataD to dictionary structure avr_dataD\n",
    "    folderN1  ----    shot_typeN1   ----  Avr_inf instances\n",
    "                      shot_typeN2   ----  Avr_inf instances\n",
    "                     ....\n",
    "    folderN2  ----    shot_typeN1   ----  Avr_inf instances\n",
    "                      shot_typeN2   ----  Avr_inf instances\n",
    "                     ....\n",
    "    By default does fit each average image 2D-gauss\"\"\"\n",
    "    avr_dataD = dict()\n",
    "    w = FloatProgress(min=0, max = len(dataD), value=0)\n",
    "    w.description='Averaging in progress...'\n",
    "    display(w)\n",
    "    for folderN, folder_dict in dataD.items():\n",
    "        w.value += 1\n",
    "        avr_dataD[folderN] = dict()\n",
    "        temp_dict = avr_dataD[folderN]\n",
    "        for shot_typeN, shot_list in folder_dict.items():\n",
    "            if shot_list != []:\n",
    "                temp_dict[shot_typeN] = Avr_inf(shot_list, do_fit2D)\n",
    "    w.bar_style='success'\n",
    "    w.description = 'Averaging Done'\n",
    "    print('Averaging is complited')\n",
    "    return avr_dataD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_directory_average(d_tuple,do_fit2D):\n",
    "    \"\"\"Function to use in parallel average\"\"\"\n",
    "    folderN, folder_dict = d_tuple\n",
    "    temp_dict = dict()\n",
    "    for shot_typeN, shot_list in folder_dict.items():\n",
    "        if shot_list != []:\n",
    "            temp_dict[shot_typeN] = Avr_inf(shot_list, do_fit2D)\n",
    "    return folderN, temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_value(obj, attribute, index):\n",
    "    \"\"\"retruns obj.attibute[index] or obj.attribute if index is not defined\"\"\"\n",
    "    if index != None:\n",
    "        return getattr(obj,attribute)[index]\n",
    "    else:\n",
    "        return getattr(obj,attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constract_data(dictionary, shot_typeN, attribute, index = None):\n",
    "    \"\"\"The most usefull tool. Returns x_data and y_data list already suitable for plotting (i.e. with the same length)\n",
    "    dictionary - the dictionary to extract data from (i.e. dataD or avr_dataD)\n",
    "    shot_typeN - type of the shot sequence (the last number in image name)\n",
    "    attribute - which attribute of data instance to use !!!look at help for Avr_inf and Image_Image and all their \n",
    "    parents\n",
    "    index - if attribute is a list, specifies which paticular data to use\"\"\"\n",
    "    x_data = array([])\n",
    "    y_data = array([])\n",
    "    import collections\n",
    "    for folderN, f_dict in dictionary.items():\n",
    "        if f_dict == {}:\n",
    "            continue\n",
    "        if isinstance(f_dict[shot_typeN], collections.Iterable):\n",
    "            temp_arr = [get_value(elem, attribute, index) for elem in f_dict[shot_typeN]]\n",
    "        else:\n",
    "            temp_arr = [get_value(f_dict[shot_typeN], attribute, index)]\n",
    "        y_data = append(y_data, temp_arr)\n",
    "        x_data = append(x_data, ones(len(temp_arr)) * folderN)\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sift(dataD, confidence_interval = 0.1):\n",
    "    \"\"\"Sifts (filters) data on empty images by using average information and comperes centers  of 1D gaussian fits.\n",
    "    If difference is larger the 'confidence_interval' from the average value, the image would be removed from dataD\"\"\"\n",
    "    w = FloatProgress(min=0, max = len(dataD), value=0)\n",
    "    w.description='Sifting in progress...'\n",
    "    display(w)\n",
    "    for folderN, folder_dict in dataD.items():\n",
    "        w.value += 1\n",
    "        for shot_typeN, shot_list in folder_dict.items():\n",
    "            #print(folderN, shot_typeN)\n",
    "            avr_inf = Avr_inf(shot_list, do_fit2D=False)\n",
    "            to_remove = []\n",
    "            for elem in shot_list:\n",
    "                if abs(elem.x_data_fit[1]-avr_inf.x_data_fit[1])/avr_inf.x_data_fit[1] > confidence_interval or \\\n",
    "                    abs(elem.y_data_fit[1]-avr_inf.y_data_fit[1])/avr_inf.y_data_fit[1] > confidence_interval:\n",
    "                        to_remove.append(elem)\n",
    "            for elem in to_remove:\n",
    "                print('remove element',shot_list.index(elem), elem.image_url )\n",
    "                shot_list.remove(elem)\n",
    "    w.bar_style='success'\n",
    "    w.description = 'Sifting Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_directory_sift(d_tuple, confidence_interval):\n",
    "    \"\"\"Function to use in parallel sigting\n",
    "    !!! works slower than without parallelism\"\"\"\n",
    "    folderN, folder_dict = d_tuple\n",
    "    temp_dict = dict()\n",
    "    for shot_typeN, shot_list in folder_dict.items():\n",
    "        #print(folderN, shot_typeN)\n",
    "        avr_inf = Avr_inf(shot_list, do_fit2D=False)\n",
    "        to_remove = []\n",
    "        for elem in shot_list:\n",
    "            if abs(elem.x_data_fit[1]-avr_inf.x_data_fit[1])/avr_inf.x_data_fit[1] > confidence_interval or \\\n",
    "                abs(elem.y_data_fit[1]-avr_inf.y_data_fit[1])/avr_inf.y_data_fit[1] > confidence_interval:\n",
    "                    to_remove.append(elem)\n",
    "        for elem in to_remove:\n",
    "            print('remove element',shot_list.index(elem), elem.image_url )\n",
    "            shot_list.remove(elem)\n",
    "    return folderN, folder_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise_avr_image(dictionary, signal_shot, calibration_shot, attribute, index=None, do_fit2D = True):\n",
    "    \"\"\"normalize image from evarage dictionary using attribute[index] value - usually 'total' or 'x_data_fit[0]'\n",
    "        returns constracted dictionary (like what returns 'average_data()' function\"\"\"\n",
    "    norm_data = dict()\n",
    "    w = FloatProgress(min=0, max=len(dictionary),value=0)\n",
    "    w.description='Normalizing in progress...'\n",
    "    display(w)\n",
    "    for folderN, f_dict in dictionary.items():\n",
    "        w.value += 1\n",
    "        norm_data[folderN] = dict()\n",
    "        norm_data[folderN][signal_shot] = Image_Fitted(f_dict[signal_shot].image / \n",
    "                                          get_value(f_dict[calibration_shot],attribute,index),do_fit2D)\n",
    "    w.bar_style='success'\n",
    "    w.description = 'Normalizing Done'\n",
    "    print('Normalization is complited')\n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise_individual_image(dictionary, signal_shot, calibration_shot, attribute, index=None, do_fit2D = False):\n",
    "    \"\"\"normalize each image using attribute[index] value - usually 'total' or 'x_data_fit[0]'\n",
    "        returns constracted dictionary (like what returns 'load_data()' function\"\"\"\n",
    "    norm_data = dict()\n",
    "    w = FloatProgress(min=0, max=len(dictionary),value=0)\n",
    "    w.description='Normalizing in progress...'\n",
    "    display(w)\n",
    "    for folderN, f_dict in dictionary.items():\n",
    "        w.value += 1\n",
    "        calibrated_images = []\n",
    "        for s_elem in f_dict[signal_shot]:\n",
    "            c_elems = [c_elem for c_elem in f_dict[calibration_shot] if c_elem.shotN == s_elem.shotN]\n",
    "            if c_elems == []:\n",
    "                print('s_elem.image_url has no calibration image')\n",
    "                continue\n",
    "            calibrated_images = append(calibrated_images, \n",
    "                                       Image_Fitted(s_elem.image / get_value(c_elems[0],attribute,index), do_fit2D))\n",
    "        if calibrated_images != []:\n",
    "            norm_data[folderN] = dict()\n",
    "            norm_data[folderN][signal_shot] = calibrated_images\n",
    "    w.bar_style='success'\n",
    "    w.description = 'Normalizing Done'\n",
    "    print('Normalization is complited')\n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class N_atoms:\n",
    "  \"\"\"\n",
    "  Natoms = N_atoms(gain, exp, power, width, delta) - создать объект класса\n",
    "  Natoms(signal) - считает число атомов. по сути в этом месте просто умножение на число\n",
    "  signal - параметр фита\n",
    "  [exposure]=us\n",
    "  [power]=mW\n",
    "  [width]=mm\n",
    "  [delta]=MHz\n",
    "  [gamma]=MHz\n",
    "  [angle]=1\n",
    "  \"\"\"\n",
    "  def __init__(self, gain=100, exposure=300, power=2.7, width=2.27, delta = 0, gamma = 10, angle = 1./225, Isat = 0.18, hw = 6.6*3/0.41*10**(-11)):\n",
    "    self.s = 2*power/3.141592654/width**2/Isat\n",
    "    self.rho = self.s/2/(1+self.s+(2*delta/gamma)**2)\n",
    "    self.p = 9.69*0.001/100/exposure/2.718281828**(3.85/1000*gain)/gamma/hw/angle/self.rho\n",
    "  \n",
    "  def __call__(self, signal):\n",
    "    return signal*self.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real_size(x, binning=2, pixel_size = 22.3/4):\n",
    "    return x * binning * pixel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_data(data_lists, points):\n",
    "    \"\"\" Drop points from all lists in data_list, mask is constracted using first list in data_lists\"\"\"\n",
    "    mask = array([not(x in points) for x in data_lists[0]])\n",
    "    res = []\n",
    "    for data_list in data_lists:\n",
    "        list.append(res,data_list[mask])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data2_sort(x,y):\n",
    "    \"\"\" Sort both array x and y using x-array as criteria\"\"\"\n",
    "    res = array(sorted(zip(x,y), key=lambda x: x[0]))\n",
    "    return res[:,0],res[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
